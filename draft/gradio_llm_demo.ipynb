{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "from neollm import MyLLM\n",
    "from neollm.utils.preprocess import dict2json\n",
    "from neollm.utils.postprocess import json2dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7885\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7885/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mPARENT\u001b[0m\n",
      "MyLLM(ChatBotLLM) ----------------------------------------------------------------------------------\n",
      "\u001b[34m[inputs]\u001b[0m\n",
      "{\n",
      "  \"user_prompt\": \"こんにちは\"\n",
      "}\n",
      "\u001b[34m[messages]\u001b[0m\n",
      " \u001b[32msystem\u001b[0m\n",
      "  あなたは優秀なAIアシスタントです\n",
      " \u001b[32muser\u001b[0m\n",
      "  こんにちは\n",
      " \u001b[32massistant\u001b[0m\n",
      "  こんにちは！お困りごとはありますか？お手伝いできることがあれば、なんでもお知らせくださいね。\n",
      "\u001b[34m[outputs]\u001b[0m\n",
      "\"こんにちは！お困りごとはありますか？お手伝いできることがあれば、なんでもお知らせくださいね。\"\n",
      "\u001b[34m[client_settings]\u001b[0m -\n",
      "\u001b[34m[llm_settings]\u001b[0m {'platform': 'openai', 'temperature': 0.2, 'max_tokens': 1000, 'model': 'gpt-3.5-turbo-1106'}\n",
      "\u001b[34m[metadata]\u001b[0m 0.9s; 68(29+39)tokens; $6.8e-05; ¥0.0095\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[41mPARENT\u001b[0m\n",
      "MyLLM(ChatBotLLM) ----------------------------------------------------------------------------------\n",
      "\u001b[34m[inputs]\u001b[0m\n",
      "{\n",
      "  \"user_prompt\": \"私はkokiです\"\n",
      "}\n",
      "\u001b[34m[messages]\u001b[0m\n",
      " \u001b[32msystem\u001b[0m\n",
      "  あなたは優秀なAIアシスタントです\n",
      " \u001b[32muser\u001b[0m\n",
      "  こんにちは\n",
      " \u001b[32msystem\u001b[0m\n",
      "  こんにちは！お困りごとはありますか？お手伝いできることがあれば、なんでもお知らせくださいね。\n",
      " \u001b[32muser\u001b[0m\n",
      "  私はkokiです\n",
      " \u001b[32massistant\u001b[0m\n",
      "  はじめまして、Kokiさん！何か質問やお手伝いできることはありますか？\n",
      "\u001b[34m[outputs]\u001b[0m\n",
      "\"はじめまして、Kokiさん！何か質問やお手伝いできることはありますか？\"\n",
      "\u001b[34m[client_settings]\u001b[0m -\n",
      "\u001b[34m[llm_settings]\u001b[0m {'platform': 'openai', 'temperature': 0.2, 'max_tokens': 1000, 'model': 'gpt-3.5-turbo-1106'}\n",
      "\u001b[34m[metadata]\u001b[0m 1.1s; 112(81+31)tokens; $0.00011; ¥0.016\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[41mPARENT\u001b[0m\n",
      "MyLLM(ChatBotLLM) ----------------------------------------------------------------------------------\n",
      "\u001b[34m[inputs]\u001b[0m\n",
      "{\n",
      "  \"user_prompt\": \"私の名前は？\"\n",
      "}\n",
      "\u001b[34m[messages]\u001b[0m\n",
      " \u001b[32msystem\u001b[0m\n",
      "  あなたは優秀なAIアシスタントです\n",
      " \u001b[32muser\u001b[0m\n",
      "  こんにちは\n",
      " \u001b[32msystem\u001b[0m\n",
      "  こんにちは！お困りごとはありますか？お手伝いできることがあれば、なんでもお知らせくださいね。\n",
      " \u001b[32muser\u001b[0m\n",
      "  私はkokiです\n",
      " \u001b[32msystem\u001b[0m\n",
      "  はじめまして、Kokiさん！何か質問やお手伝いできることはありますか？\n",
      " \u001b[32muser\u001b[0m\n",
      "  私の名前は？\n",
      " \u001b[32massistant\u001b[0m\n",
      "  申し訳ありません、Kokiさんとお伝えいただきましたね。お名前を覚えました。お気軽に何か質問があればどうぞ。\n",
      "\u001b[34m[outputs]\u001b[0m\n",
      "\"申し訳ありません、Kokiさんとお伝えいただきましたね。お名前を覚えました。お気軽に何か質問があればどうぞ。\"\n",
      "\u001b[34m[client_settings]\u001b[0m -\n",
      "\u001b[34m[llm_settings]\u001b[0m {'platform': 'openai', 'temperature': 0.2, 'max_tokens': 1000, 'model': 'gpt-3.5-turbo-1106'}\n",
      "\u001b[34m[metadata]\u001b[0m 0.9s; 180(126+54)tokens; $0.00018; ¥0.025\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[41mPARENT\u001b[0m\n",
      "MyLLM(ChatBotLLM) ----------------------------------------------------------------------------------\n",
      "\u001b[34m[inputs]\u001b[0m\n",
      "{\n",
      "  \"user_prompt\": \"最初に質問したことは何でしたっけ？\"\n",
      "}\n",
      "\u001b[34m[messages]\u001b[0m\n",
      " \u001b[32msystem\u001b[0m\n",
      "  あなたは優秀なAIアシスタントです\n",
      " \u001b[32muser\u001b[0m\n",
      "  こんにちは\n",
      " \u001b[32msystem\u001b[0m\n",
      "  こんにちは！お困りごとはありますか？お手伝いできることがあれば、なんでもお知らせくださいね。\n",
      " \u001b[32muser\u001b[0m\n",
      "  私はkokiです\n",
      " \u001b[32msystem\u001b[0m\n",
      "  はじめまして、Kokiさん！何か質問やお手伝いできることはありますか？\n",
      " \u001b[32muser\u001b[0m\n",
      "  私の名前は？\n",
      " \u001b[32msystem\u001b[0m\n",
      "  申し訳ありません、Kokiさんとお伝えいただきましたね。お名前を覚えました。お気軽に何か質問があればどうぞ。\n",
      " \u001b[32muser\u001b[0m\n",
      "  最初に質問したことは何でしたっけ？\n",
      " \u001b[32massistant\u001b[0m\n",
      "  最初の質問は、「私はkokiです」というものでしたね。それ以外にも何か質問があればお知らせください。お手伝いできることがあればお手伝いします。\n",
      "\u001b[34m[outputs]\u001b[0m\n",
      "\"最初の質問は、「私はkokiです」というものでしたね。それ以外にも何か質問があればお知らせください。お手伝いできることがあればお手伝いします。\"\n",
      "\u001b[34m[client_settings]\u001b[0m -\n",
      "\u001b[34m[llm_settings]\u001b[0m {'platform': 'openai', 'temperature': 0.2, 'max_tokens': 1000, 'model': 'gpt-3.5-turbo-1106'}\n",
      "\u001b[34m[metadata]\u001b[0m 1.3s; 267(204+63)tokens; $0.00027; ¥0.037\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[41mPARENT\u001b[0m\n",
      "MyLLM(ChatBotLLM) ----------------------------------------------------------------------------------\n",
      "\u001b[34m[inputs]\u001b[0m\n",
      "{\n",
      "  \"user_prompt\": \"あなたに使用されているモデルは？\"\n",
      "}\n",
      "\u001b[34m[messages]\u001b[0m\n",
      " \u001b[32msystem\u001b[0m\n",
      "  あなたは優秀なAIアシスタントです\n",
      " \u001b[32muser\u001b[0m\n",
      "  こんにちは\n",
      " \u001b[32msystem\u001b[0m\n",
      "  こんにちは！お困りごとはありますか？お手伝いできることがあれば、なんでもお知らせくださいね。\n",
      " \u001b[32muser\u001b[0m\n",
      "  私はkokiです\n",
      " \u001b[32msystem\u001b[0m\n",
      "  はじめまして、Kokiさん！何か質問やお手伝いできることはありますか？\n",
      " \u001b[32muser\u001b[0m\n",
      "  私の名前は？\n",
      " \u001b[32msystem\u001b[0m\n",
      "  申し訳ありません、Kokiさんとお伝えいただきましたね。お名前を覚えました。お気軽に何か質問があればどうぞ。\n",
      " \u001b[32muser\u001b[0m\n",
      "  最初に質問したことは何でしたっけ？\n",
      " \u001b[32msystem\u001b[0m\n",
      "  最初の質問は、「私はkokiです」というものでしたね。それ以外にも何か質問があればお知らせください。お手伝いできることがあればお手伝いします。\n",
      " \u001b[32muser\u001b[0m\n",
      "  あなたに使用されているモデルは？\n",
      " \u001b[32massistant\u001b[0m\n",
      "  私のバックエンドには、自然言語処理や機械学習の技術が組み込まれています。詳細なモデル名やアーキテクチャについては、開発元のディープラーニングモデルや機械学習モデルが使用されています。\n",
      "\u001b[34m[outputs]\u001b[0m\n",
      "\"私のバックエンドには、自然言語処理や機械学習の技術が組み込まれています。詳細なモデル名やアーキテクチャについては、開発元のディープラーニングモデルや機械学習モデルが使用されています。\"\n",
      "\u001b[34m[client_settings]\u001b[0m -\n",
      "\u001b[34m[llm_settings]\u001b[0m {'platform': 'openai', 'temperature': 0.2, 'max_tokens': 1000, 'model': 'gpt-3.5-turbo-1106'}\n",
      "\u001b[34m[metadata]\u001b[0m 1.7s; 396(290+106)tokens; $0.0004; ¥0.055\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "class ChatBotLLM(MyLLM):\n",
    "    def __init__(self, message_history: list, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.message_history = message_history\n",
    "\n",
    "    def _preprocess(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        system_prompt = \"あなたは優秀なAIアシスタントです\"\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "\n",
    "        # 過去の会話履歴を追加\n",
    "        for prompt, response in self.message_history:\n",
    "            messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "            messages.append({\"role\": \"system\", \"content\": response})\n",
    "\n",
    "        user_prompt = f\"{inputs['user_prompt']}\"\n",
    "        messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "        return messages\n",
    "\n",
    "    def _postprocess(self, response) -> str:\n",
    "        output = response.choices[0][\"message\"][\"content\"]\n",
    "        return output\n",
    "\n",
    "\n",
    "def chat_with_gpt(prompt, message_history):\n",
    "    try:\n",
    "        llm = ChatBotLLM(\n",
    "            llm_settings={\"temperature\": 0.2, \"max_tokens\": 1000},\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            platform=\"openai\",\n",
    "            stream_verbose=False,  # TODO: stremaの実装\n",
    "            message_history=message_history,\n",
    "        )\n",
    "        inputs = {\"user_prompt\": prompt}\n",
    "        outputs = llm(inputs=inputs)\n",
    "        message_history.append((prompt, outputs))\n",
    "        return \"\", message_history\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# Chat with neoLLM\")\n",
    "\n",
    "    chatbot = gr.Chatbot()\n",
    "\n",
    "    input = gr.Textbox(show_label=False, placeholder=\"Message neoLLM...\")\n",
    "    input.submit(fn=chat_with_gpt, inputs=[input, chatbot], outputs=[input, chatbot])\n",
    "\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7890\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7890/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mPARENT\u001b[0m\n",
      "MyLLM(ChatBotLLM) ----------------------------------------------------------------------------------\n",
      "\u001b[34m[inputs]\u001b[0m\n",
      "{\n",
      "  \"user_prompt\": \"こんにちは\"\n",
      "}\n",
      "\u001b[34m[messages]\u001b[0m\n",
      " \u001b[32msystem\u001b[0m\n",
      "  あなたは優秀なAIアシスタントです\n",
      " \u001b[32muser\u001b[0m\n",
      "  こんにちは\n",
      " \u001b[32massistant\u001b[0m\n",
      "  こんにちは！お困りごとはありますか？何かお手伝いできることはありますか？\n",
      "\u001b[34m[outputs]\u001b[0m\n",
      "\"こんにちは！お困りごとはありますか？何かお手伝いできることはありますか？\"\n",
      "\u001b[34m[client_settings]\u001b[0m -\n",
      "\u001b[34m[llm_settings]\u001b[0m {'platform': 'openai', 'temperature': 0.2, 'max_tokens': 1000, 'model': 'gpt-3.5-turbo-1106'}\n",
      "\u001b[34m[metadata]\u001b[0m 0.8s; 59(29+30)tokens; $5.9e-05; ¥0.0083\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def chat_with_gpt(prompt, message_history):\n",
    "    try:\n",
    "        llm = ChatBotLLM(\n",
    "            llm_settings={\"temperature\": 0.2, \"max_tokens\": 1000},\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            platform=\"openai\",\n",
    "            stream_verbose=False,  # TODO: stremaの実装\n",
    "            message_history=message_history,\n",
    "        )\n",
    "        inputs = {\"user_prompt\": prompt}\n",
    "        outputs = llm(inputs=inputs)\n",
    "        message_history.append((prompt, outputs))\n",
    "        return \"\", message_history\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "\n",
    "def clear_history():\n",
    "    return \"\", []\n",
    "\n",
    "\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# Chat with neoLLM\")\n",
    "\n",
    "    chatbot = gr.Chatbot()\n",
    "    input_text = gr.Textbox(show_label=False, placeholder=\"Message neoLLM...\")\n",
    "\n",
    "    input_text.submit(fn=chat_with_gpt, inputs=[\n",
    "                      input_text, chatbot], outputs=[input_text, chatbot])\n",
    "    submit_button = gr.Button(\"送信\")\n",
    "    submit_button.click(fn=chat_with_gpt, inputs=[\n",
    "                        input_text, chatbot], outputs=[input_text, chatbot])\n",
    "\n",
    "    clear_button = gr.Button(\"履歴をクリア\")\n",
    "    clear_button.click(fn=clear_history, inputs=[],\n",
    "                       outputs=[input_text, chatbot])\n",
    "\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 履歴を加味\n",
    "- 送信ボタンとEnterボタンの追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7896\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7896/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[41mPARENT\u001b[0m\n",
      "MyLLM(ChatBotLLM) ----------------------------------------------------------------------------------\n",
      "\u001b[34m[inputs]\u001b[0m\n",
      "{\n",
      "  \"user_prompt\": \"hello\"\n",
      "}\n",
      "\u001b[34m[messages]\u001b[0m\n",
      " \u001b[32msystem\u001b[0m\n",
      "  あなたは優秀なAIアシスタントです\n",
      " \u001b[32muser\u001b[0m\n",
      "  hello\n",
      " \u001b[32massistant\u001b[0m\n",
      "  Hello! How can I assist you today?\n",
      "\u001b[34m[outputs]\u001b[0m\n",
      "\"Hello! How can I assist you today?\"\n",
      "\u001b[34m[client_settings]\u001b[0m -\n",
      "\u001b[34m[llm_settings]\u001b[0m {'platform': 'openai', 'temperature': 0.2, 'max_tokens': 1000, 'model': 'gpt-3.5-turbo-1106'}\n",
      "\u001b[34m[metadata]\u001b[0m 0.6s; 38(29+9)tokens; $3.8e-05; ¥0.0053\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[41mPARENT\u001b[0m\n",
      "MyLLM(ChatBotLLM) ----------------------------------------------------------------------------------\n",
      "\u001b[34m[inputs]\u001b[0m\n",
      "{\n",
      "  \"user_prompt\": \"i am ishi\"\n",
      "}\n",
      "\u001b[34m[messages]\u001b[0m\n",
      " \u001b[32msystem\u001b[0m\n",
      "  あなたは優秀なAIアシスタントです\n",
      " \u001b[32muser\u001b[0m\n",
      "  i am ishi\n",
      " \u001b[32massistant\u001b[0m\n",
      "  Hello Ishi! How can I assist you today?\n",
      "\u001b[34m[outputs]\u001b[0m\n",
      "\"Hello Ishi! How can I assist you today?\"\n",
      "\u001b[34m[client_settings]\u001b[0m -\n",
      "\u001b[34m[llm_settings]\u001b[0m {'platform': 'openai', 'temperature': 0.2, 'max_tokens': 1000, 'model': 'gpt-3.5-turbo-1106'}\n",
      "\u001b[34m[metadata]\u001b[0m 0.8s; 43(32+11)tokens; $4.3e-05; ¥0.006\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\u001b[41mPARENT\u001b[0m\n",
      "MyLLM(ChatBotLLM) ----------------------------------------------------------------------------------\n",
      "\u001b[34m[inputs]\u001b[0m\n",
      "{\n",
      "  \"user_prompt\": \"what is my name?\"\n",
      "}\n",
      "\u001b[34m[messages]\u001b[0m\n",
      " \u001b[32msystem\u001b[0m\n",
      "  あなたは優秀なAIアシスタントです\n",
      " \u001b[32muser\u001b[0m\n",
      "  what is my name?\n",
      " \u001b[32massistant\u001b[0m\n",
      "  I'm sorry, I don't have access to your personal information, including your name. If you'd like to share your name with me, I'd be happy to address you by it.\n",
      "\u001b[34m[outputs]\u001b[0m\n",
      "\"I'm sorry, I don't have access to your personal information, including your name. If you'd like to share your name with me, I'd be happy to address you by it.\"\n",
      "\u001b[34m[client_settings]\u001b[0m -\n",
      "\u001b[34m[llm_settings]\u001b[0m {'platform': 'openai', 'temperature': 0.2, 'max_tokens': 1000, 'model': 'gpt-3.5-turbo-1106'}\n",
      "\u001b[34m[metadata]\u001b[0m 1.0s; 72(33+39)tokens; $7.2e-05; ¥0.01\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def chat_with_gpt(prompt, message_history):\n",
    "    try:\n",
    "        llm = ChatBotLLM(\n",
    "            llm_settings={\"temperature\": 0.2, \"max_tokens\": 1000},\n",
    "            model=\"gpt-3.5-turbo-1106\",\n",
    "            platform=\"openai\",\n",
    "            stream_verbose=False,  # TODO: stremaの実装\n",
    "            message_history=message_history,\n",
    "        )\n",
    "        inputs = {\"user_prompt\": prompt}\n",
    "        outputs = llm(inputs=inputs)\n",
    "        message_history.append((prompt, outputs))\n",
    "        return \"\", message_history\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "\n",
    "def clear_history():\n",
    "    return \"\", []\n",
    "\n",
    "\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# Chat with neoLLM\")\n",
    "\n",
    "    chatbot = gr.Chatbot()\n",
    "    input_text = gr.Textbox(show_label=False, placeholder=\"Message neoLLM...\")\n",
    "\n",
    "    input_text.submit(fn=chat_with_gpt, inputs=[\n",
    "                      input_text, chatbot], outputs=[input_text, chatbot])\n",
    "    submit_button = gr.Button(\"Send\")\n",
    "    submit_button.click(fn=chat_with_gpt, inputs=[\n",
    "                        input_text, chatbot], outputs=[input_text, chatbot])\n",
    "\n",
    "    clear_button = gr.Button(\"New Chat\")\n",
    "    clear_button.click(fn=clear_history, inputs=[],\n",
    "                       outputs=[input_text, chatbot])\n",
    "\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## プルダウンでモデルを選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7900\n",
      "\n",
      "Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7900/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def chat_with_gpt(prompt, model, message_history):\n",
    "    try:\n",
    "        llm_settings = {\"temperature\": 0.2, \"max_tokens\": 1000}\n",
    "        llm = ChatBotLLM(\n",
    "            llm_settings=llm_settings,\n",
    "            model=model,  # プルダウンから選択されたモデルを使用\n",
    "            platform=\"openai\",\n",
    "            stream_verbose=False,  # TODO: stremaの実装\n",
    "            message_history=message_history,\n",
    "        )\n",
    "        inputs = {\"user_prompt\": prompt}\n",
    "        outputs = llm(inputs=inputs)\n",
    "        message_history.append((prompt, outputs))\n",
    "        return \"\", message_history\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\", message_history\n",
    "\n",
    "\n",
    "def clear_history():\n",
    "    return \"\", []\n",
    "\n",
    "\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# Chat with neoLLM\")\n",
    "\n",
    "    model_dropdown = gr.Dropdown(\n",
    "        label=\"Models\",\n",
    "        choices=[\n",
    "            \"gpt-3.5-turbo-0125\",\n",
    "            \"gpt-4\",\n",
    "            \"gpt-4-0125-preview\",\n",
    "            \"gpt-4-turbo-preview\"\n",
    "        ],\n",
    "        value=\"gpt-3.5-turbo-0125\",\n",
    "    )\n",
    "\n",
    "    chatbot = gr.Chatbot()\n",
    "    input_text = gr.Textbox(show_label=False, placeholder=\"Message neoLLM...\")\n",
    "\n",
    "    input_text.submit(fn=chat_with_gpt, inputs=[input_text, model_dropdown, chatbot], outputs=[input_text, chatbot])\n",
    "    submit_button = gr.Button(\"Send\")\n",
    "    submit_button.click(fn=chat_with_gpt, inputs=[input_text, model_dropdown, chatbot], outputs=[input_text, chatbot])\n",
    "\n",
    "    clear_button = gr.Button(\"+ New Chat\")\n",
    "    clear_button.click(fn=clear_history, inputs=[], outputs=[input_text, chatbot])\n",
    "\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## パラメータの調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "css = \"\"\"\n",
    "/* チャットボットのユーザーメッセージの背景色を変更 */\n",
    ".message.user {\n",
    "    background: #06c755 !important;\n",
    "    color: white;\n",
    "}\n",
    "\n",
    "/* チャットボットのボットメッセージの背景色を変更 */\n",
    ".message.bot {\n",
    "    background: #007BFF !important;\n",
    "    color: white;\n",
    "}\n",
    "\n",
    "/* ボタンのスタイルをカスタマイズ */\n",
    "button {\n",
    "    background-color: #06c755;\n",
    "    color: white;\n",
    "    border: none;\n",
    "    padding: 10px 20px;\n",
    "    text-align: center;\n",
    "    text-decoration: none;\n",
    "    display: inline-block;\n",
    "    font-size: 16px;\n",
    "    margin: 4px 2px;\n",
    "    transition-duration: 0.4s;\n",
    "    cursor: pointer;\n",
    "    border-radius: 5px;\n",
    "}\n",
    "\n",
    "button:hover {\n",
    "    background-color: white;\n",
    "    color: #06c755;\n",
    "}\n",
    "\n",
    "/* ドロップダウンのスタイルをカスタマイズ */\n",
    ".select {\n",
    "    width: 100%;\n",
    "    padding: 12px 20px;\n",
    "    margin: 8px 0;\n",
    "    display: inline-block;\n",
    "    border: 1px solid #ccc;\n",
    "    border-radius: 4px;\n",
    "    box-sizing: border-box;\n",
    "}\n",
    "\n",
    "/* スライダーのスタイルをカスタマイズ */\n",
    ".slider {\n",
    "    -webkit-appearance: none;\n",
    "    width: 100%;\n",
    "    height: 15px;\n",
    "    border-radius: 5px;\n",
    "    background: #06c755;\n",
    "    outline: none;\n",
    "    opacity: 0.7;\n",
    "    -webkit-transition: .2s;\n",
    "    transition: opacity .2s;\n",
    "}\n",
    "\n",
    ".slider:hover {\n",
    "    opacity: 1;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7905\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7905/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "\n",
    "def chat_with_gpt(prompt, model, temperature, message_history):\n",
    "    try:\n",
    "        llm_settings = {\"temperature\": temperature, \"max_tokens\": 1000}  # Sliderからの入力を使用\n",
    "        llm = ChatBotLLM(\n",
    "            llm_settings=llm_settings,\n",
    "            model=model,  # プルダウンから選択されたモデルを使用\n",
    "            platform=\"openai\",\n",
    "            stream_verbose=False,  # TODO: stremaの実装\n",
    "            message_history=message_history,\n",
    "        )\n",
    "        inputs = {\"user_prompt\": prompt}\n",
    "        outputs = llm(inputs=inputs)\n",
    "        message_history.append((prompt, outputs))\n",
    "        return \"\", message_history\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\", message_history\n",
    "\n",
    "\n",
    "def clear_history():\n",
    "    return \"\", []\n",
    "\n",
    "with gr.Blocks(css=css) as app:\n",
    "    # gr.Markdown(\"# Chat with neoLLM\")\n",
    "\n",
    "    model_dropdown = gr.Dropdown(\n",
    "        label=\"Models\",\n",
    "        choices=[\"gpt-3.5-turbo-0125\", \"gpt-4\", \"gpt-4-0125-preview\", \"gpt-4-turbo-preview\"],\n",
    "        value=\"gpt-3.5-turbo-0125\",\n",
    "    )\n",
    "\n",
    "    # temperatureの値を調整するためのSliderを追加\n",
    "    temperature_slider = gr.Slider(minimum=0.0, maximum=1.0, step=0.01, value=0.2, label=\"Temperature\")\n",
    "\n",
    "    chatbot = gr.Chatbot()\n",
    "    input_text = gr.Textbox(show_label=False, placeholder=\"Message neoLLM...\")\n",
    "\n",
    "    input_text.submit(\n",
    "        fn=chat_with_gpt,\n",
    "        inputs=[input_text, model_dropdown, temperature_slider, chatbot],\n",
    "        outputs=[input_text, chatbot],\n",
    "    )\n",
    "    submit_button = gr.Button(\"Send\")\n",
    "    submit_button.click(\n",
    "        fn=chat_with_gpt,\n",
    "        inputs=[input_text, model_dropdown, temperature_slider, chatbot],\n",
    "        outputs=[input_text, chatbot],\n",
    "    )\n",
    "\n",
    "    clear_button = gr.Button(\"+ New Chat\")\n",
    "    clear_button.click(fn=clear_history, inputs=[], outputs=[input_text, chatbot])\n",
    "\n",
    "app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
